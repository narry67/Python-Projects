import os
from pathlib import Path
import pandas as pd
import textblob
from textblob import TextBlob, Word
from textatistic import Textatistic
import nltk
from operator import itemgetter
#nltk.download('stopwords')
from nltk.corpus import stopwords
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import imageio
import itertools
import spacy



nlp_lg = spacy.load('en_core_web_lg')
mask_image = imageio.imread('mask.jpeg')
stops = stopwords.words('english')
#part 1 download documents
play = Path("SScomedy.txt").read_text()
path = Path.cwd() / 'EAPraven.txt'
with open(path, mode='r', encoding="utf8") as file:
    poem = file.read()
satire = Path("Secclesiastes.txt").read_text()
#end part 1
#part 2 (a) compute word counts not in stop words
blobplay = TextBlob(play)
blobpoem = TextBlob(poem)
blobsatire = TextBlob(satire)
itemsplay = blobplay.word_counts.items()
itemspoem = blobpoem.word_counts.items()
itemssatire = blobsatire.word_counts.items()
stops.extend(["“","”","’","—"])  # dont want to count frequency of these "words"

itemsplay = [item for item in itemsplay if item[0] not in stops] #Selection via list comprehension
itemspoem = [item for item in itemspoem if item[0] not in stops] #Selection via list comprehension
itemssatire = [item for item in itemssatire if item[0] not in stops] #Selection via list comprehension
#end part 2 (a)
#part (b) sort items and get top 25 most frequent then display graph
splay = sorted(itemsplay, key=itemgetter(1), reverse=True)
spoem = sorted(itemspoem, key=itemgetter(1), reverse=True)
ssatire = sorted(itemssatire, key=itemgetter(1), reverse=True)
topplay = splay[:25]
toppoem = spoem[:25]
topsatire = ssatire[:25]


df1 = pd.DataFrame(topplay, columns=['word', 'count'])
df2 = pd.DataFrame(toppoem, columns=['word', 'count'])
df3 = pd.DataFrame(topsatire, columns=['word', 'count'])

df1.plot.bar(x='word', y='count', legend=False, title = "Shakespeare Play")
df2.plot.bar(x='word', y='count', legend=False, title = "Edgar Allen Poe Poem")
df3.plot.bar(x='word', y='count', legend=False, title = "Solomon Ecclesiastes")
plt.gcf().tight_layout()
plt.show()
plt.clf()
#end part b
#start part c wordcloud
wordcloud1 = WordCloud(width=1000, height=1000,
    colormap='prism', mask=mask_image, background_color='white', max_words = 100)
wordcloud1 = wordcloud1.fit_words(dict(splay))
wordcloud1 = wordcloud1.to_file('RomeoAndJulietHeart.png')
plt.figure(figsize=(10,10))
plt.imshow(wordcloud1)
plt.show()

wordcloud2 = WordCloud(width=1000, height=1000,
    colormap='prism', mask=mask_image, background_color='white', max_words = 100)
wordcloud2 = wordcloud2.fit_words(dict(spoem))
wordcloud2 = wordcloud2.to_file('RomeoAndJulietHeart.png')
plt.figure(figsize=(10,10))
plt.imshow(wordcloud2)
plt.show()

wordcloud3 = WordCloud(width=1000, height=1000,
    colormap='prism', mask=mask_image, background_color='white', max_words = 100)
wordcloud3 = wordcloud3.fit_words(dict(ssatire))
wordcloud3 = wordcloud3.to_file('RomeoAndJulietHeart.png')
plt.figure(figsize=(10,10))
plt.imshow(wordcloud3)
plt.show()
#end part c
# number 3 compute readibility
readability1 = Textatistic(play)
readability2 = Textatistic(poem)
readability3 = Textatistic(satire)
print(readability1.dict())
print(readability2.dict())
print(readability3.dict())

print(f'average of play {(readability1.dict()["fleschkincaid_score"] + readability1.dict()["gunningfog_score"] + readability1.dict()["smog_score"])/3}')
print(f'average of poem {(readability2.dict()["fleschkincaid_score"] + readability2.dict()["gunningfog_score"] + readability2.dict()["smog_score"])/3}')
print(f'average of satire {(readability3.dict()["fleschkincaid_score"] + readability3.dict()["gunningfog_score"] + readability3.dict()["smog_score"])/3}')
#end 3

#spacy spacy spacy spacy spacy spacy spacy spacy spacy spacy note that entity type graphs are produced before names
#start 4 computer similarity
document1 = nlp_lg(play)
document2 = nlp_lg(poem)
document3 = nlp_lg(satire)
print(f'the similarity between 1 and 2: {document1.similarity(document2)}\n the similarity between 1 and 3: {document1.similarity(document3)}\n the similarity between 2 and 3: {document2.similarity(document3)}')
#end 4
#start 5 find names of entities and entity types dict 1-3 represent entities types and occurances and 4-6 represnet names
dict1 = {}
dict2 = {}
dict3 = {}
dict4 = {}
dict5 = {}
dict6 = {}
for entity in document1.ents:
    print(f'document 1: {entity.text}: {entity.label_}')
    try:
        dict1[str(entity.label_)]+=1
        dict4[str(entity.text)] += 1
    except KeyError:
        dict1[str(entity.label_)] = 1
        dict4[str(entity.text)] = 1
for entity in document2.ents:
    print(f'document 2: {entity.text}: {entity.label_}')
    try:
        dict2[str(entity.label_)] += 1
        dict5[str(entity.text)] += 1
    except KeyError:
        dict2[str(entity.label_)] = 1
        dict5[str(entity.text)] = 1
for entity in document3.ents:
    print(f'document 3: {entity.text}: {entity.label_}')
    try:
        dict3[str(entity.label_)] += 1
        dict6[str(entity.text)] += 1
    except KeyError:
        dict3[str(entity.label_)] = 1
        dict6[str(entity.text)] = 1

dict1 = sorted(dict1.items(), key=itemgetter(1), reverse=True)
dict2 = sorted(dict2.items(), key=itemgetter(1), reverse=True)
dict3 = sorted(dict3.items(), key=itemgetter(1), reverse=True)
dict4 = sorted(dict4.items(), key=itemgetter(1), reverse=True)
dict5 = sorted(dict5.items(), key=itemgetter(1), reverse=True)
dict6 = sorted(dict6.items(), key=itemgetter(1), reverse=True)
#display entity types
DFa = pd.DataFrame(dict1, columns=['entity', 'count'])
DFb = pd.DataFrame(dict2, columns=['entity', 'count'])
DFc = pd.DataFrame(dict3, columns=['entity', 'count'])
plt.clf()
DFa.plot.bar(x='entity', y='count', legend=False, title = "Shakespeare Play")
DFb.plot.bar(x='entity', y='count', legend=False, title = "Edgar Allen Poe Poem")
DFc.plot.bar(x='entity', y='count', legend=False, title = "Solomon Ecclesiastes")
plt.gcf().tight_layout()
plt.show()
# now turning to entity names
dict4 = dict(itertools.islice(dict(dict4).items(), 20))
dict5 = dict(itertools.islice(dict(dict5).items(), 20))
dict6 = dict(itertools.islice(dict(dict6).items(), 20))
plt.clf()
plt.bar(range(len(dict4.keys())), list(dict4.values()), align='center')
plt.xticks(range(len(dict4.keys())), list(dict4.keys()),rotation = 90)
plt.show()
plt.clf()
plt.bar(range(len(dict5.keys())), list(dict5.values()), align='center')
plt.xticks(range(len(dict5.keys())), list(dict5.keys()),rotation = 90)
plt.show()
plt.clf()
plt.bar(range(len(dict6.keys())), list(dict6.values()), align='center')
plt.xticks(range(len(dict6.keys())), list(dict6.keys()),rotation = 90)
plt.gcf().tight_layout()
plt.show()